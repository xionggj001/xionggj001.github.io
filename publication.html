<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Welcome to Guojun Xiong's Homepage
</title>
</head>
<body>
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
    var pageTracker = _gat._getTracker("UA-129163640-1");
    pageTracker._trackPageview();
} catch(err) {}</script>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Guojun Xiong</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="index.html" class="current">Publication</a></div>
<div class="menu-item"><a href="teaching.html">Activities</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=FIBwLnoAAAAJ&hl=en">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications 
</h1>
<ul>


<h2>2026
</h2>
<ul>
</li>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://arxiv.org/pdf/2509.16399?">VORTEX: Aligning Task Utility and Human Preferences
through LLM-Guided Reward Shaping </a><br />
<b>Guojun Xiong</b>,  Milind Tambe. AAAI 2026. <a href="https://arxiv.org/pdf/2509.16399?">[arXiv]</a> 
</p>
</li>

</ul>

  
<h2>2025
</h2>
<ul>
</li>
</li>
  <li><p><span style="font-weight: bold;">[US Patent]</span> <a href="https://patents.google.com/patent/US20250293968A1/en">Multi-Agent Reinforcement Learning Aided Smart Agriculture Networks</a><br />
Jianlin Guo, <b>Guojun Xiong</b>, Kieran Parsons, Philip Orlik. USPTO 2025. <a href="https://patents.google.com/patent/US20250293968A1/en">[arXiv]</a>
</p>
</li>
  <li><p><span style="font-weight: bold;">[NeurIPS]</span> <a href="https://arxiv.org/pdf/2505.23062?">Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data</a><br />
Lingkai Kong*, Haichuan Wang*, Tonghan Wang, <b>Guojun Xiong</b>, Milind Tambe. NeurIPS 2025 (<span style="font-weight: bold;">Spotlight</span>). <a href="https://arxiv.org/pdf/2505.23062?">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ACL]</span> <a href="https://arxiv.org/abs/2502.11433">FLAG-TRADER: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading</a><br />
<b>Guojun Xiong</b>, Zhiyang Deng, Keyi Wang, Yupeng Cao, Haohang Li, Yangyang Yu, Xueqing Peng, MINGQUAN LIN, Kaleb E Smith, Xiao-Yang Liu, Jimin Huang, Sophia Ananiadou, Qianqian Xie. ACL 2025 Findings. <a href="https://arxiv.org/abs/2502.11433">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ACM SIGMETRICS]</span> <a href="https://www.arxiv.org/pdf/2504.11569">Multi-Agent Reinforcement Learning for Decentralized Reservoir
Management via Murmuration Intelligence</a><br />
Heming Fu, <b>Guojun Xiong</b>, Jian Li, Shan Lin. ACM SIGMETRICS Workshop 2025 (AI Crossroads: Systems, Energy, and Applications). <a href="https://www.arxiv.org/pdf/2504.11569">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ICLR]</span> <a href="https://openreview.net/pdf?id=zMtCKA4APY">MPAW: Multi-Preference Alignment through Weak Model Collaboration for Efficient and Flexible LLM Decoding</a><br />
Nuo Chen, <b>Guojun Xiong</b>, Bingsheng He. ICLR 2025 Workshop (Scaling Self-Improving Foundation Models). <a href="https://openreview.net/pdf?id=zMtCKA4APY">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ICLR]</span> <a href="https://openreview.net/pdf?id=BfUDZGqCAu">On the Linear Speedup of Personalized Federated Reinforcement Learning with Shared Representations</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Daniel Jiang, Jian Li. ICLR 2025. <a href="https://openreview.net/pdf?id=BfUDZGqCAu">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ICLR]</span> <a href="https://openreview.net/pdf?id=2iYVBqRHK4">Direct Online Preference Learning for Restless Multi-Armed Bandits with Preference Feedback</a><br />
<b>Guojun Xiong</b>, Ujwal Dinesha, Debajoy Mukherjee, Jian Li, Srinivas Shakkottai. ICLR 2025. <a href="https://openreview.net/pdf?id=2iYVBqRHK4">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[IEEE ICC]</span> <a href="https://arxiv.org/pdf/xxxx">Multi-Agent Reinforcement Learning Aided Smart Agriculture Networks</a><br />
 <b>Guojun Xiong</b>, Jianlin Guo, Kieran Parsons,  Yukimasa Nagai, Takenori Sumi, Philip Orlik, Jian Li. IEEE ICC 2025. <a href="https://arxiv.org/pdf/xxxx">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[AAMAS]</span> <a href="https://arxiv.org/pdf/2501.06103">Finite-Horizon Single-Pull Restless Bandits: An Efficient Index Policy For Scarce Resource Allocation</a><br />
 <b>Guojun Xiong</b>, Haichuan Wang, Yuqi Pan, Saptarshi Mandal, Sanket Shah, Niclas Boehmer, Milind Tambe. AAMAS 2025. <a href="https://arxiv.org/pdf/2501.06103">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://arxiv.org/pdf/2408.14001">Decentralized Federated Learning with Model Caching on Mobile Agents</a><br />
Xiaoyu Wang, <b>Guojun Xiong</b>, Houwei Cao, Jian Li, Yong Liu. AAAI 2025. (<span style="font-weight: bold;">Oral Presentation</span>) <a href="https://arxiv.org/pdf/2408.14001">[arXiv]</a>
</p>
</li>
</ul>
  
<h2>2024
</h2>
<ul>
</li>
</li>
<li><p><span style="font-weight: bold;">[Neurips]</span> <a href="https://arxiv.org/pdf/2402.12659">The Finben: An Holistic Financial Benchmark for Large Language Models</a><br />
Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru He, Mengxi Xiao, Dong Li, Yongfu Dai, Duanyu Feng, Yijing Xu, Haoqiang Kang, Ziyan Kuang, Chenhan Yuan, Kailai Yang, Zheheng Luo, Tianlin Zhang, Zhiwei Liu, <b>Guojun Xiong</b>, et al. NeurIPS 2024. <a href="https://arxiv.org/pdf/2402.12659">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[Neurips]</span> <a href="https://arxiv.org/abs/2407.06567">FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making</a><br />
Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, Koduvayur Subbalakshmi, <b>Guojun Xiong</b>, Yueru He, Jimin Huang, Dong Li, Qianqian Xie. NeurIPS 2024. <a href="https://arxiv.org/abs/2407.06567">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ACM MobiHoc]</span> <a href="https://arxiv.org/pdf/2306.06559">Straggler-resilient decentralized learning via adaptive asynchronous updates</a><br />
<b>Guojun Xiong*</b>, Gang Yan*, Shiqiang Wang, Jian Li. AIoT 2024 (In conjunction with ACM MobiHoc 2024) <a href="https://arxiv.org/pdf/2306.06559">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[RLC Workshop]</span> <a href="https://deployable-rl.github.io/">Personalized Federated Reinforcement Learning
with Shared Representations</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Daniel Jiang, Jian Li.   Reinforcement Learning Conference 2024 (Deployable RL Workshop: From Research to Practice) <a href="https://deployable-rl.github.io/">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[IEEE TWC]</span> <a href="https://arxiv.org/pdf/2404.16920">Structured Reinforcement Learning for Delay-Optimal Data Transmission in Dense mmWave Networks</a><br />
Shufan Wang, <b>Guojun Xiong</b>, Shichen Zhang, Huacheng Zeng, Jian Li, Shivendra Panwar.  (IEEE Transaction on Wireless Communication 2024) <a href="https://arxiv.org/pdf/2404.16920">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[IEEE/ACM TON]</span> <a href="https://arxiv.org/pdf/2202.13187">Whittle Index-based Q-Learning for Wireless Edge Caching with Linear Function Approximation</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Jian Li, Rahul Singh. (IEEE/ACM Transactions on Networking 2024) <a href="https://arxiv.org/pdf/2202.13187">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ICML]</span> <a href="https://arxiv.org/pdf/2405.00950">Provably Efficient Reinforcement Learning for Adversarial Restless Multi-Armed Bandits with Unknown Transitions and Bandit Feedback</a><br />
<b>Guojun Xiong</b>, Jian Li. ICML 2024. <a href="https://arxiv.org/pdf/2405.00950">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29543">DePRL: Achieving Linear Convergence Speedup in Personalized Decentralized Learning with Shared Representations</a><br />
<b>Guojun Xiong</b>, Gang Yan, Shiqiang Wang, Jian Li. AAAI 2024. <a href="https://arxiv.org/pdf/2312.10815">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29489">Online Restless Multi-Armed Bandits with Long-Term Fairness Constraints</a><br />
Shufan Wang, <b>Guojun Xiong</b>, Jian Li. AAAI 2024.  <a href="https://arxiv.org/pdf/2312.10303">[arXiv]</a>
</p>
</li>
</ul>
  
<h2>2023
</h2>
<ul>
</li>
</li>
<li><p><span style="font-weight: bold;">[Neurips]</span> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/5c7c66dfc9f93f0c738947f3b1c13832-Paper-Conference.pdf">Finite-Time Analysis of Whittle Index based Q-Learning for Restless Multi-Armed Bandits with Neural Network Function Approximation</a><br />
<b>Guojun Xiong</b>, Jian Li. NeurIPS 2023. <a href="https://arxiv.org/abs/2310.02147">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[IEEE/ACM TON]</span> <a href="https://ieeexplore.ieee.org/abstract/document/10021290">Reinforcement Learning for Dynamic Dimensioning of Cloud Caches: A Restless Bandit Approach</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Gang Yan, Jian Li. (IEEE/ACM Transactions on Networking 2023). <a href="https://ieeexplore.ieee.org/abstract/document/10021290">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26251">Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits</a><br />
<b>Guojun Xiong</b>, Jian Li. AAAI 2023. (<b>Oral Presentation</b>) <a href="https://arxiv.org/abs/2212.06279">[arXiv]</a>
</p>
</li>
</ul>
  
<h2>2022
</h2>
<ul>
</li>
</li>
<li><p><span style="font-weight: bold;">[Neurips]</span> <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/71f003060ce1e8b6b4856023b67cda5d-Paper-Conference.pdf">Learning Infinite-Horizon Average-Reward Restless Multi-Action Bandits via Index Awareness</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Jian Li.  NuerIPS 2022. <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/71f003060ce1e8b6b4856023b67cda5d-Paper-Conference.pdf">[paper]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[ACM MobiHoc]</span> <a href="https://dl.acm.org/doi/abs/10.1145/3492866.3549726"> Index-Aware Reinforcement Learning for Adaptive Video Streaming at the Wireless Edge</a><br />
<b>Guojun Xiong</b>, Xudong Qin, Bin Li, Rahul Singh, Jian Li. ACM Mobihoc 2022. <a href="https://dl.acm.org/doi/abs/10.1145/3492866.3549726">[arXiv]</a>
</p>
</li>
<li><p><span style="font-weight: bold;">[IEEE INFOCOM]</span> <a href="https://dl.acm.org/doi/abs/10.1109/INFOCOM48880.2022.9796809">Reinforcement Learning for Dynamic Dimensioning of Cloud Caches: A Restless Bandit Approach</a><br />
<b>Guojun Xiong</b>, Shufan Wang, Gang Yan, Jian Li. IEEE INFOCOM, 2022. <a href="https://dl.acm.org/doi/abs/10.1109/INFOCOM48880.2022.9796809">[arXiv]</a> 
</p>
</li>
<li><p><span style="font-weight: bold;">[AAAI]</span> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20852">Reinforcement Learning Augmented Asymptotically Optimal Index Policies for Finite-Horizon Restless Bandits </a><br />
<b>Guojun Xiong</b>, Jian Li, Rahul Singh. AAAI 2022. (<b>Oral Presentation</b>) <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20852">[arXiv]</a> 
</p>
</li>
</ul>
  
<h2>2020
</h2>
<ul>
</li>
</li>
<li><p><span style="font-weight: bold;">[IEEE TSP]</span> <a href="https://ieeexplore.ieee.org/document/9250692">Optimality conditions of
performance-guaranteed power minimization in mimo networks: A distributed algorithm and its
feasibility </a><br />
<b>Guojun Xiong</b>, Taejoon Kim, David J. Love, Erik Perrins. (IEEE Transaction on Signal Processing 2020). <a href="https://ieeexplore.ieee.org/document/9250692">[arXiv]</a> 
</p>
</li>

</ul>
  
<h2>Preprints
</h2>
<ul>
</li>
<li><p>Rule-Bottleneck Reinforcement Learning: Joint Explanation and Decision Optimization for Resource Allocation with Language Agents<br />
<b>Guojun Xiong*</b>, Mauricio Tec*, Haichuan Wang, Milind Tambe. <a href="https://arxiv.org/abs/2502.10732">[arXiv]</a>
</p>
</li>



<div id="footer">
<div id="footer-text">
Page generated 2024-06-18 09:32:20 PDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>





